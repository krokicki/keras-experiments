{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Based on https://www.pyimagesearch.com/2016/08/01/lenet-convolutional-neural-network-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def show(cv_image):\n",
    "    img = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize = (20,10))\n",
    "    plt.imshow(img, interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def showGrey(img):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import SGD, Adadelta\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3214 images\n"
     ]
    }
   ],
   "source": [
    "# load data set\n",
    "\n",
    "size=(28, 28)\n",
    "\n",
    "def image_to_feature_vector(image, size=size):\n",
    "    return cv2.resize(image, size)\n",
    "\n",
    "def rotate(image, angle=90):\n",
    "    rows = image.shape[0]\n",
    "    cols = image.shape[1]\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),angle,1)\n",
    "    return cv2.warpAffine(image,M,(cols,rows))\n",
    "    \n",
    "dataset_dir = \"/Users/rokickik/Downloads/Workstation/orientation/20x/left\"\n",
    "imagePaths = list(paths.list_images(dataset_dir))\n",
    "\n",
    "raw_data = []\n",
    "raw_labels = []\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    \n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)    \n",
    "    \n",
    "    #if i%2==0:\n",
    "    raw_data.append(image_to_feature_vector(image))\n",
    "    raw_labels.append(\"left\")\n",
    "    #else:\n",
    "    right = rotate(image, angle=-90)\n",
    "    raw_data.append(image_to_feature_vector(right))\n",
    "    raw_labels.append(\"right\")\n",
    "        \n",
    "print(\"Loaded %d images\" % len(raw_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (2410, 28, 28, 1)\n",
      "Test data shape: (804, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# encode the labels, converting them from strings to integers\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(raw_labels)\n",
    "\n",
    "if False:\n",
    "    # show data\n",
    "    for i in range(0,len(raw_data)):\n",
    "        print(\"%s\"%raw_labels[i])\n",
    "        showGrey(raw_data[i].reshape(28,28))\n",
    "        if i>50:\n",
    "            break\n",
    "        \n",
    "# scale the input image pixels to the range [0, 1], then transform\n",
    "# the labels into vectors in the range [0, num_classes] -- this\n",
    "# generates a vector for each label where the index of the label\n",
    "# is set to `1` and all other entries to `0`\n",
    "data = np.array(raw_data) / 255.0\n",
    "\n",
    "data = data[:, :, :, np.newaxis]\n",
    "labels = np_utils.to_categorical(labels, 2)\n",
    " \n",
    "# partition the data into training and testing splits, using 75%\n",
    "# of the data for training and the remaining 25% for testing\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(\n",
    "    data, labels, test_size=0.25, random_state=42)\n",
    "    \n",
    "print(\"Train data shape: \"+ str(trainData.shape))\n",
    "print(\"Test data shape: \"+ str(testData.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network architectures \n",
    "\n",
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes, weightsPath=None):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(20, (5, 5), activation='relu', padding=\"same\", input_shape=input_shape))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        model.add(Conv2D(50, (5, 5), activation='relu', padding=\"same\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500, activation='relu'))\n",
    "        model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "        if weightsPath is not None:\n",
    "            model.load_weights(weightsPath)\n",
    " \n",
    "        return model\n",
    "        \n",
    "class LeNet2:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes, weightsPath=None):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, (3, 3), activation='relu', padding=\"same\", input_shape=input_shape))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "        if weightsPath is not None:\n",
    "            model.load_weights(weightsPath)\n",
    " \n",
    "        return model\n",
    "    \n",
    "class LeNet3:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes, weightsPath=None):\n",
    "        model = Sequential()\n",
    "        print(input_shape)\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu', input_shape=input_shape))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "        if weightsPath is not None:\n",
    "            model.load_weights(weightsPath)\n",
    " \n",
    "        return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 1,217,602\n",
      "Trainable params: 1,217,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = LeNet3.build((size[0],size[1],1), classes=2, weightsPath=None)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2410/2410 [==============================] - 6s 3ms/step - loss: 0.6101 - acc: 0.8328\n",
      "Epoch 2/20\n",
      "2410/2410 [==============================] - 7s 3ms/step - loss: 0.3649 - acc: 0.9946\n",
      "Epoch 3/20\n",
      "2410/2410 [==============================] - 8s 3ms/step - loss: 0.1493 - acc: 0.9988\n",
      "Epoch 4/20\n",
      "2410/2410 [==============================] - 8s 3ms/step - loss: 0.0681 - acc: 0.9988\n",
      "Epoch 5/20\n",
      "2410/2410 [==============================] - 8s 3ms/step - loss: 0.0392 - acc: 0.9988\n",
      "Epoch 6/20\n",
      "2410/2410 [==============================] - 8s 3ms/step - loss: 0.0276 - acc: 0.9992\n",
      "Epoch 7/20\n",
      "2410/2410 [==============================] - 7s 3ms/step - loss: 0.0224 - acc: 0.9992\n",
      "Epoch 8/20\n",
      "2410/2410 [==============================] - 9s 4ms/step - loss: 0.0189 - acc: 0.9992\n",
      "Epoch 9/20\n",
      "2410/2410 [==============================] - 9s 4ms/step - loss: 0.0152 - acc: 0.9988\n",
      "Epoch 10/20\n",
      "2410/2410 [==============================] - 7s 3ms/step - loss: 0.0148 - acc: 0.9988\n",
      "Epoch 11/20\n",
      "2410/2410 [==============================] - 6s 3ms/step - loss: 0.0128 - acc: 0.9992\n",
      "Epoch 12/20\n",
      "2410/2410 [==============================] - 9s 4ms/step - loss: 0.0122 - acc: 0.9988\n",
      "Epoch 13/20\n",
      "2410/2410 [==============================] - 9s 4ms/step - loss: 0.0113 - acc: 0.9992\n",
      "Epoch 14/20\n",
      "2410/2410 [==============================] - 7s 3ms/step - loss: 0.0107 - acc: 0.9992\n",
      "Epoch 15/20\n",
      "2410/2410 [==============================] - 7s 3ms/step - loss: 0.0100 - acc: 0.9992\n",
      "Epoch 16/20\n",
      "2410/2410 [==============================] - 8s 3ms/step - loss: 0.0114 - acc: 0.9992\n",
      "Epoch 17/20\n",
      "2410/2410 [==============================] - 8s 3ms/step - loss: 0.0087 - acc: 0.9992\n",
      "Epoch 18/20\n",
      "2410/2410 [==============================] - 9s 4ms/step - loss: 0.0099 - acc: 0.9992\n",
      "Epoch 19/20\n",
      "2410/2410 [==============================] - 8s 3ms/step - loss: 0.0100 - acc: 0.9992\n",
      "Epoch 00019: early stopping\n",
      "804/804 [==============================] - 1s 1ms/step\n",
      "Test set loss: 0.0011, accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "verbose=1\n",
    "epochs=20\n",
    "batch_size=128\n",
    "opt = SGD(lr=0.01)\n",
    "#opt = Adadelta()\n",
    "model.compile(loss=categorical_crossentropy, optimizer=opt, metrics=[\"accuracy\"])\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=2, verbose=1, mode='auto')\n",
    "model.fit(trainData, trainLabels, batch_size=batch_size, epochs=epochs, callbacks=[early_stopping], verbose=verbose)\n",
    "\n",
    "# evaluate\n",
    "(loss, accuracy) = model.evaluate(testData, testLabels, batch_size=batch_size, verbose=verbose)\n",
    "print(\"Test set loss: {:.4f}, accuracy: {:.2f}%\".format(loss, accuracy * 100))\n",
    "\n",
    "# save weights to disk\n",
    "model_filepath = \"/Users/rokickik/Downloads/Workstation/orientation/lenet.weights\"\n",
    "model.save(model_filepath, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n",
      "All correct\n"
     ]
    }
   ],
   "source": [
    "# test on actual right-oriented data\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "test_dir = \"/Users/rokickik/Downloads/Workstation/orientation/20x/right\"\n",
    "\n",
    "# initialize the class labels \n",
    "CLASSES = [\"left\", \"right\"]\n",
    " \n",
    "# load the network\n",
    "print(\"loading model\")\n",
    "model = load_model(model_filepath)\n",
    "\n",
    "all_correct = True\n",
    "\n",
    "# loop over our testing images\n",
    "for imagePath in paths.list_images(test_dir):\n",
    "    # load the image, resize it to a fixed 32 x 32 pixels (ignoring\n",
    "    # aspect ratio), and then extract features from it\n",
    "    filename = imagePath[imagePath.rfind(\"/\") + 1:]\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    features = image_to_feature_vector(image) / 255.0\n",
    "    features = features[np.newaxis, :, :, np.newaxis]\n",
    "    \n",
    "    probs = model.predict(features)[0]\n",
    "    prediction = probs.argmax(axis=0)\n",
    "\n",
    "    if prediction!=1:\n",
    "        print(\"INCORRECT PREDICTION for %s\" % (filename))\n",
    "        all_correct = False\n",
    "    if False:\n",
    "        # draw the class and probability on the test image and display it\n",
    "        label = \"{}: {:.2f}%\".format(CLASSES[prediction], probs[prediction] * 100)\n",
    "        print(\"Classified {} as {}\".format(filename, label))\n",
    "        cv2.putText(image, label, (40, 95), cv2.FONT_HERSHEY_SIMPLEX, 3.0, (255, 255, 255), 10)\n",
    "        showGrey(image)\n",
    "\n",
    "if all_correct:\n",
    "    print(\"All correct\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Not yet working\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# construct the set of hyperparameters to tune\n",
    "#params = {\"n_neighbors\": np.arange(1, 31, 2),\n",
    "#          \"metric\": [\"euclidean\", \"cityblock\"]}\n",
    "\n",
    "#grid = GridSearchCV(model, params)\n",
    "grid = RandomizedSearchCV(model, params)\n",
    "start = time.time()\n",
    "grid.fit(trainData, trainLabels)\n",
    "print(\"Grid search took {:.2f} seconds\".format(time.time() - start))\n",
    "acc = grid.score(testData, testLabels)\n",
    "print(\"Grid search accuracy: {:.2f}%\".format(acc * 100))\n",
    "print(\"Grid search best parameters: {}\".format(grid.best_params_))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
